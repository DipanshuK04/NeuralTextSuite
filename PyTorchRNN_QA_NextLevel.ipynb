{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uVT_3SjwW_pP",
        "outputId": "cdded6cd-307d-4b84-a633-f42ab6fceb7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is the boiling point of water in Celsius?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "df = pd.read_csv('/content/100_Unique_QA_Dataset.csv')\n",
        "df['question'][4]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace('?','')\n",
        "  text = text.replace(\"'\",'')\n",
        "  return text.split()\n",
        "st = tokenize(df['question'][4])\n",
        "st"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE4gcMSVsxMy",
        "outputId": "5ec0d491-1c21-4532-fbaa-e95fcada2e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'is', 'the', 'boiling', 'point', 'of', 'water', 'in', 'celsius']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {'<UNK>':0}\n",
        "def build_vocab(row):\n",
        "  tokenized_que = tokenize(row['question'])\n",
        "  tokenized_ans = tokenize(row['answer'])\n",
        "  merged_tokens = tokenized_que + tokenized_ans\n",
        "  for tok in merged_tokens:\n",
        "    if tok not in vocab:\n",
        "      vocab[tok] = len(vocab)\n",
        "  # print(merged_tokens)\n",
        "df.apply(build_vocab,axis=1)\n",
        "print(len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7fZ2s7r1rS1",
        "outputId": "3c66cd8e-710a-4b3b-b827-ce167fa5f38b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_indices(text,vocab):\n",
        "  indexed_text = []\n",
        "  for tok in tokenize(text):\n",
        "    if tok in vocab:\n",
        "      indexed_text.append(vocab[tok])\n",
        "    else:\n",
        "      indexed_text.append(vocab['<UNK>'])\n",
        "  return indexed_text\n",
        "\n",
        "text_to_indices(df['question'][4],vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWKC_5UCF0gn",
        "outputId": "edc159e1-e611-45a8-cb86-b9489110a065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 24, 25, 5, 26, 19, 27]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset,DataLoader\n",
        "class QADataset(Dataset):\n",
        "\n",
        "  def __init__(self,df,vocab):\n",
        "    self.df = df\n",
        "    self.vocab = vocab\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    row = self.df.iloc[idx]\n",
        "    question = text_to_indices(row['question'],self.vocab)\n",
        "    answer = text_to_indices(row['answer'],self.vocab)\n",
        "    return torch.tensor(question),torch.tensor(answer)\n",
        "\n",
        "dataset = QADataset(df,vocab)\n",
        "\n",
        "dataloader = DataLoader(dataset,shuffle = True,batch_size=1)\n"
      ],
      "metadata": {
        "id": "jdGTuO1VINMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = nn.Embedding(num_embeddings=len(vocab),embedding_dim = 10)\n",
        "print(dataset[0][0])\n",
        "a = x(dataset[0][0])\n",
        "print(a.shape)\n",
        "b = nn.RNN(10,4)\n",
        "print(b(a)) # RNN gives 2 output the 2nd one is the final output as its time series , the first one is intermediate output\n",
        "# due to this we cant use sequential for this"
      ],
      "metadata": {
        "id": "MbgoAk1AJdhC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0559000-2878-49c0-f78b-f6c753290e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5, 6])\n",
            "torch.Size([6, 10])\n",
            "(tensor([[ 0.8095, -0.0420,  0.5664,  0.5459],\n",
            "        [ 0.8267,  0.1697,  0.8288,  0.4065],\n",
            "        [ 0.7428, -0.0391, -0.4393, -0.1213],\n",
            "        [ 0.7679,  0.4496,  0.2577,  0.0430],\n",
            "        [ 0.2064, -0.3706,  0.1613,  0.0528],\n",
            "        [ 0.2760, -0.8273,  0.7246, -0.3887]], grad_fn=<SqueezeBackward1>), tensor([[ 0.2760, -0.8273,  0.7246, -0.3887]], grad_fn=<SqueezeBackward1>))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class simpleRNN(nn.Module):\n",
        "  def __init__(self,vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size,embedding_dim=50)\n",
        "    self.RNN = nn.RNN(50,64,batch_first=True)\n",
        "    self.fc = nn.Linear(64,vocab_size)\n",
        "  def forward(self,x):\n",
        "    embedding_layer = self.embedding(x)\n",
        "    hidden,final = self.RNN(embedding_layer)\n",
        "    fc = self.fc(final.squeeze(0))\n",
        "    return fc\n",
        "\n",
        "lr = 0.001\n",
        "epochs = 20\n",
        "\n",
        "model = simpleRNN(len(vocab))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  loss_per =  0\n",
        "  for batch_features,batch_labels in dataloader:\n",
        "    y_pred = model(batch_features)\n",
        "    # print(y_pred.shape)\n",
        "    # print(batch_labels.shape)\n",
        "    loss = criterion(y_pred,batch_labels.squeeze(1))\n",
        "    loss_per += loss.item()\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f\"epoch :{epoch} , loss : {loss_per}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cSjJDK8kZey",
        "outputId": "acebfdb6-d7ab-4050-8c85-56cd4874abbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :0 , loss : 526.3599934577942\n",
            "epoch :1 , loss : 461.7219581604004\n",
            "epoch :2 , loss : 385.3423066139221\n",
            "epoch :3 , loss : 319.2793312072754\n",
            "epoch :4 , loss : 265.3177890777588\n",
            "epoch :5 , loss : 215.34896862506866\n",
            "epoch :6 , loss : 170.37253379821777\n",
            "epoch :7 , loss : 131.9568995833397\n",
            "epoch :8 , loss : 99.4663667678833\n",
            "epoch :9 , loss : 75.6221244931221\n",
            "epoch :10 , loss : 57.34659454226494\n",
            "epoch :11 , loss : 44.16183368861675\n",
            "epoch :12 , loss : 34.604509860277176\n",
            "epoch :13 , loss : 27.678925216197968\n",
            "epoch :14 , loss : 22.59835061430931\n",
            "epoch :15 , loss : 18.6551845818758\n",
            "epoch :16 , loss : 15.762975797057152\n",
            "epoch :17 , loss : 13.324132144451141\n",
            "epoch :18 , loss : 11.502157889306545\n",
            "epoch :19 , loss : 9.960929203778505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, question, threshold=0.5):\n",
        "\n",
        "  # convert question to numbers\n",
        "  numerical_question = text_to_indices(question, vocab)\n",
        "\n",
        "  # tensor\n",
        "  question_tensor = torch.tensor(numerical_question).unsqueeze(0)\n",
        "\n",
        "  # send to model\n",
        "  output = model(question_tensor)\n",
        "\n",
        "  # convert logits to probs\n",
        "  probs = torch.nn.functional.softmax(output, dim=1)\n",
        "\n",
        "  # find index of max prob\n",
        "  value, index = torch.max(probs, dim=1)\n",
        "\n",
        "  if value < threshold:\n",
        "    print(\"I don't know\")\n",
        "  else:\n",
        "    print(list(vocab.keys())[index])\n",
        "\n"
      ],
      "metadata": {
        "id": "T782UOkc4iaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, \"What is the square root of 64\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woki11RY41qn",
        "outputId": "b11cb00e-40a9-43c5-8330-79eb3e8d1d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    }
  ]
}